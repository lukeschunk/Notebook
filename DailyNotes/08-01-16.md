### Datastream
* Long term vision of data stream = people have been doing scrapes for a long time.
* Scrapes are prone to breakage, things get requested in different orders.
* Imperative = telling the computer what to do at each step is a poor model for this stuff. What if we thought of every response as an event, and we modeled it as a set of reactors.
* Or - imperative flows aren't all that bad, but the way we fix them is bad. So we have a grammar that is the way the user interacts with the web page (ie any time we have an exception, png and html dump of the page)
* Capybara is a testing language, long term capybara won't be the right DSL for us to do all our scrapes in.
* 10 mil aggs /day should be our planned capacity
* APR, available/current balance, account ownership information - ie which people are on the account that have access to it.
* numberic values are always represented as currency, same with percentages


Pitfalls
* testing with one member information - ie might only have a savings account
*

* Grunt has an action subscriber instance, job identifier ie, 'agg luke's account', then makes an HTTP call to datastream
* Rorshack MDX - sessions controller -> loads a gem for the given institution, creates a client object and calls authenticate on that client object.

Chase Web Gem - it's job is if you pass in all the persistant information, it will get as much data as it can. It's a mostly stateless implementation

Rorshack MDX - understanding the MDX protocol and persistance

* We're hoping the output from the extension will replace the 'chase web' gem.


1. Open up a PR when we update gh-pages.
2.
